{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROJECT: PREDICTING TYPE OF CRIME IN TORONTO\n",
    "\n",
    "\n",
    "#Notes: \n",
    "\n",
    "#Approach is to numeric encode the data set and run a RF model to see performance and then to create a second data set\n",
    "#that is one-hot encoded to test it's performance on the same model. \n",
    "\n",
    "#--------------------------------------------------#\n",
    "\n",
    "#1) IMPORT LIBRARIES\n",
    "\n",
    "#Computation and Structuring:\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "#Modeling:\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#Testing:\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "#--------------------------------------------------#\n",
    "\n",
    "#2) DATA IMPORT AND PRE-PROCESSING\n",
    "\n",
    "#import full data set\n",
    "df = pd.read_csv('F:\\THesis\\Dataset\\New\\Crime1.csv',sep=',') \n",
    "\n",
    "#list of relevant columns for model\n",
    "col_list = ['occurrenceyear','occurrencemonth','occurrenceday','occurrencedayofyear','occurrencedayofweek','occurrencehour','MCI',\t'Division',\t'Hood_ID','premisetype']\n",
    "\n",
    "#dataframe created from list of relevant columns\n",
    "\n",
    "df2 = df[col_list]\n",
    "df2 = df2[df2['occurrenceyear'] > 2013] #drop \"stale\" crimes, where occurence is before 2014. Since data set is filtered based on reported date, we're ignoring these old crimes.\n",
    "\n",
    "#Factorize dependent variable column:\n",
    "\n",
    "crime_var = pd.factorize(df2['MCI']) #codes the list of crimes to a int64 variable\n",
    "df2['MCI'] = crime_var[0]\n",
    "definition_list_MCI = crime_var[1] #create an index reference so we know which crimes are coded to which factors\n",
    "\n",
    "#factorize independent variables:\n",
    "\n",
    "#factorize premisetype:\n",
    "\n",
    "premise_var = pd.factorize(df2['premisetype'])\n",
    "df2['premisetype'] = premise_var[0]\n",
    "definition_list_premise = premise_var[1] \n",
    "\n",
    "#factorize occurenceyear:\n",
    "\n",
    "year_var = pd.factorize(df2['occurrenceyear'])\n",
    "df2['occurrenceyear'] = year_var[0]\n",
    "definition_list_year = year_var[1] \n",
    "\n",
    "#factorize occurencemonth:\n",
    "\n",
    "month_var = pd.factorize(df2['occurrencemonth'])\n",
    "df2['occurrencemonth'] = month_var[0]\n",
    "definition_list_month = month_var[1] \n",
    "\n",
    "#factorize occurenceday:\n",
    "\n",
    "day_var = pd.factorize(df2['occurrenceday'])\n",
    "df2['occurenceday'] = day_var[0]\n",
    "definition_list_day = day_var[1] \n",
    "\n",
    "#factorize occurencedayofweek:\n",
    "\n",
    "dayweek_var = pd.factorize(df2['occurrencedayofweek'])\n",
    "df2['occurrencedayofweek'] = dayweek_var[0]\n",
    "definition_list_day = dayweek_var[1] \n",
    "\n",
    "#factorize division:\n",
    "\n",
    "division_var = pd.factorize(df2['Division'])\n",
    "df2['Division'] = division_var[0]\n",
    "definition_list_division = division_var[1] \n",
    "\n",
    "#factorize HOOD_ID:\n",
    "\n",
    "hood_var = pd.factorize(df2['Hood_ID'])\n",
    "df2['Hood_ID'] = hood_var[0]\n",
    "definition_list_hood = hood_var[1] \n",
    "\n",
    "#factorize occurencehour:\n",
    "\n",
    "hour_var = pd.factorize(df2['occurrencehour'])\n",
    "df2['occurrencehour'] = hour_var[0]\n",
    "definition_list_hour = hour_var[1] \n",
    "\n",
    "#factorize occurencedayofyear:\n",
    "\n",
    "dayyear_var = pd.factorize(df2['occurrencedayofyear'])\n",
    "df2['occurrencedayofyear'] = dayyear_var[0]\n",
    "definition_list_dayyear = dayyear_var[1] \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--------------------------------------------------#\n"
     ]
    }
   ],
   "source": [
    "#set X and Y:\n",
    "\n",
    "X = df2.drop(['MCI'],axis=1).values #sets x and converts to an array\n",
    "\n",
    "\n",
    "y = df2['MCI'].values #sets y and converts to an array\n",
    "\n",
    "#split the data into train and test sets for numeric encoded dataset:\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 22)\n",
    "\n",
    "#need to OneHotEncode all the X variables for input into the classification model:\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "enc_X = enc.fit_transform(X)\n",
    "\n",
    "X_train_OH, X_test_OH, y_train_OH, y_test_OH = train_test_split(enc_X, y, test_size = 0.20, random_state = 21)\n",
    "\n",
    "\n",
    "print('#--------------------------------------------------#')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 200, criterion = 'entropy', random_state = 42)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test) # Predicting the Test set results\n",
    "\n",
    "print(accuracy_score(y_test, y_pred)) #accuracy at 0.63\n",
    "#print(confusion_matrix(y_test, y_pred)) \n",
    "#print(classification_report(y_test,y_pred, target_names=definition_list_MCI)) \n",
    "\n",
    "#theft over is pulling down results. Pretty good on Assault (largest sample size) and break and enter \n",
    "\n",
    "\n",
    "#One Hot Encoded Model w/ SKLEARN:\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 42)\n",
    "classifier.fit(X_train_OH, y_train_OH)\n",
    "y_pred_OH = classifier.predict(X_test_OH) # Predicting the Test set results\n",
    "\n",
    "print(accuracy_score(y_test_OH, y_pred_OH)) #modest improvement to 0.648\n",
    "# print(confusion_matrix(y_test_OH, y_pred_OH)) \n",
    "# print(classification_report(y_test_OH,y_pred_OH, target_names=definition_list_MCI)) #modest improvement\n",
    "\n",
    "#Balanced Class Weight doesn't make a big difference for results:\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 42, class_weight='balanced')\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test) \n",
    "print(accuracy_score(y_test, y_pred)) #accuracy at 0.63\n",
    "#print(confusion_matrix(y_test, y_pred)) \n",
    "\n",
    "#--------------------------------------------------#\n",
    "\n",
    "#gradientboost performs poorly relative to randomforest\n",
    "\n",
    "grad_class = GradientBoostingClassifier(learning_rate=0.1,n_estimators = 10, random_state = 42)\n",
    "grad_class.fit(X_train_OH, y_train_OH)\n",
    "y_pred_OH = grad_class.predict(X_test_OH) # Predicting the Test set results\n",
    "\n",
    "print(accuracy_score(y_test_OH, y_pred_OH)) #modest improvement to 0.648\n",
    "print(confusion_matrix(y_test_OH, y_pred_OH)) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
